{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (4.2) K-Nearest Neighbor implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/how-to-build-knn-from-scratch-in-python-5e22b8920bd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sajepan\\.conda\\envs\\MasterThesisGPU\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Sajepan\\.conda\\envs\\MasterThesisGPU\\lib\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\n",
      "C:\\Users\\Sajepan\\.conda\\envs\\MasterThesisGPU\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "# For importing the Functions File\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from Functions.UNSW_DF import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import *\n",
    "from decimal import Decimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Preprocessed CSV Files..\n",
      "\t Train Shape:  \t (175341, 54)\n",
      "\t Test Shape:  \t (82332, 54)\n",
      "Dataset Loaded!\n"
     ]
    }
   ],
   "source": [
    "train, test = DF_preprocessed_traintest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop([\"label\"], axis=1)\n",
    "y = train[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = X.iloc[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols = X.columns\n",
    "#for df in[X]:\n",
    "#    for col in cols:\n",
    "#        df[col] = df[col].astype(float)\n",
    "#X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm (Pseudo-code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: (1) Define a function to calculate the distance between two points\n",
    "# TODO: (2) Use the distance function to get the distance between a test point and all known data points\n",
    "# TODO: (3) Sort distance measurements to find the points closest to the test point (i.e., find the nearest neighbors)\n",
    "# TODO: (4) Use majority class labels of those closest points to predict the label of the test point\n",
    "# TODO: (5) Repeat steps 1 through 4 until all test data points are classified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Define a function to calculate distance between two points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I define a function called minkowski_distance, that takes an input of two data points (a & b) and a Minkowski power parameter p, and returns the distance between the two points. Note that this function calculates distance exactly like the Minkowski formula I mentioned earlier. By making p an adjustable parameter, I can decide whether I want to calculate Manhattan distance (p=1), Euclidean distance (p=2), or some higher order of the Minkowski distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.375302232203818"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate distance between two points\n",
    "def minkowski_distance(a, b, p=1):\n",
    "    \n",
    "    # Store the number of dimensions\n",
    "    dim = len(a)\n",
    "    # Set initial distance to 0\n",
    "    distance = 0\n",
    "\n",
    "    # Calculate minkowski distance using parameter p\n",
    "    for d in range(dim):\n",
    "        distance += abs(a[d] - b[d])**p\n",
    "        \n",
    "    distance = distance**(1/p)\n",
    "    return distance\n",
    "\n",
    "minkowski_distance(a=X.iloc[0], b=X.iloc[1], p=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.375302232203818\n"
     ]
    }
   ],
   "source": [
    "a=X.iloc[0]\n",
    "b=X.iloc[1]\n",
    "p=1\n",
    "# Set initial distance to 0\n",
    "distance = 0\n",
    "dim = len(a)\n",
    "for d in range(dim):\n",
    "    distance += abs(a[d] - b[d])**p\n",
    "distance = distance**(1/p)\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def my_p_root(value, root):\n",
    "#   my_root_value = 1 / float(root)\n",
    "#   return round (Decimal(value) **\n",
    "#   Decimal(my_root_value), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def my_minkowski_distance(x, y, p_value):\n",
    "#   return (my_p_root(sum(pow(abs(a-b), p_value)\n",
    "#      for a, b in zip(x, y)), p_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Use the distance function to get distance between a test point and all known data points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For step 2, I simply repeat the minkowski_distance calculation for all labeled points in X and store them in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.788877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.142749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.227146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.641975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.955332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dist\n",
       "0   9.788877\n",
       "1   9.142749\n",
       "2   9.227146\n",
       "3  10.641975\n",
       "4   9.955332"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define an arbitrary test point\n",
    "test_pt = [4.8, 2.7, 2.5, 0.7]\n",
    "\n",
    "# Calculate distance between test_pt and all points in X\n",
    "distances = []\n",
    "\n",
    "for i in X.index:\n",
    "    distances.append(minkowski_distance(test_pt, X.iloc[i], p=1))\n",
    "    \n",
    "df_dists = pd.DataFrame(data=distances, index=X.index, columns=['dist'])\n",
    "df_dists.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sort distance measurements to find the points closest to the test point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In step 3, I use the pandas .sort_values() method to sort by distance, and return only the top 5 results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128885</th>\n",
       "      <td>7.243819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101086</th>\n",
       "      <td>7.244050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70350</th>\n",
       "      <td>7.244193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69165</th>\n",
       "      <td>7.244419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97314</th>\n",
       "      <td>7.244481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            dist\n",
       "128885  7.243819\n",
       "101086  7.244050\n",
       "70350   7.244193\n",
       "69165   7.244419\n",
       "97314   7.244481"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the 5 nearest neighbors\n",
    "df_nn = df_dists.sort_values(by=['dist'], axis=0)[:5]\n",
    "df_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Use majority class labels of those closest points to predict the label of the test point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this step, I use collections.Counter to keep track of the labels that coincide with the nearest neighbor points. I then use the .most_common() method to return the most commonly occurring label. Note: if there is a tie between two or more labels for the title of “most common” label, the one that was first encountered by the Counter() object will be the one that gets returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Create counter object to track the labels\n",
    "counter = Counter(y[df_nn.index])\n",
    "\n",
    "# Get most common label of all the nearest neighbors\n",
    "counter.most_common()[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Repeat steps 1 through 4 until all test data points are classified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, I put the code I’ve already written to work and write a function to classify the data using KNN. First, I perform a train_test_split on the data (75% train, 25% test), and then scale the data using StandardScaler(). Since KNN is distance-based, it is important to make sure that the features are scaled properly before feeding them into the algorithm.\n",
    "\n",
    "Additionally, to avoid data leakage, it is good practice to scale the features after the train_test_split has been performed. First, scale the data from the training set only (scaler.fit_transform(X_train)), and then use that information to scale the test set (scaler.tranform(X_test)). This way, I can ensure that no information outside of the training data is used to create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Split the data - 75% train, 25% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "\n",
    "# Scale the X data\n",
    "#scaler = StandardScaler()\n",
    "#X_train = scaler.fit_transform(X_train)\n",
    "#X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 131505 entries, 72254 to 128037\n",
      "Data columns (total 53 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   service_http         131505 non-null  int64  \n",
      " 1   service_others       131505 non-null  int64  \n",
      " 2   dtcpb                131505 non-null  float64\n",
      " 3   state_others         131505 non-null  int64  \n",
      " 4   sload                131505 non-null  float64\n",
      " 5   proto_ospf           131505 non-null  int64  \n",
      " 6   ct_dst_sport_ltm     131505 non-null  float64\n",
      " 7   synack               131505 non-null  float64\n",
      " 8   sbytes               131505 non-null  float64\n",
      " 9   service_ftp-data     131505 non-null  int64  \n",
      " 10  is_sm_ips_ports      131505 non-null  float64\n",
      " 11  service_-            131505 non-null  int64  \n",
      " 12  ct_src_ltm           131505 non-null  float64\n",
      " 13  ct_src_dport_ltm     131505 non-null  float64\n",
      " 14  ct_dst_ltm           131505 non-null  float64\n",
      " 15  service_ssh          131505 non-null  int64  \n",
      " 16  sjit                 131505 non-null  float64\n",
      " 17  proto_igmp_icmp_rtp  131505 non-null  int64  \n",
      " 18  swin                 131505 non-null  float64\n",
      " 19  dload                131505 non-null  float64\n",
      " 20  dttl                 131505 non-null  float64\n",
      " 21  dur                  131505 non-null  float64\n",
      " 22  service_pop3         131505 non-null  int64  \n",
      " 23  state_FIN            131505 non-null  int64  \n",
      " 24  sttl                 131505 non-null  float64\n",
      " 25  ct_srv_src           131505 non-null  float64\n",
      " 26  state_CON            131505 non-null  int64  \n",
      " 27  stcpb                131505 non-null  float64\n",
      " 28  dbytes               131505 non-null  float64\n",
      " 29  service_smtp         131505 non-null  int64  \n",
      " 30  sinpkt               131505 non-null  float64\n",
      " 31  state_RST            131505 non-null  int64  \n",
      " 32  ct_state_ttl         131505 non-null  float64\n",
      " 33  proto_others         131505 non-null  int64  \n",
      " 34  dinpkt               131505 non-null  float64\n",
      " 35  sloss                131505 non-null  float64\n",
      " 36  proto_udp            131505 non-null  int64  \n",
      " 37  dpkts                131505 non-null  float64\n",
      " 38  ct_srv_dst           131505 non-null  float64\n",
      " 39  smean                131505 non-null  float64\n",
      " 40  ackdat               131505 non-null  float64\n",
      " 41  proto_tcp            131505 non-null  int64  \n",
      " 42  service_dns          131505 non-null  int64  \n",
      " 43  dloss                131505 non-null  float64\n",
      " 44  rate                 131505 non-null  float64\n",
      " 45  proto_arp            131505 non-null  int64  \n",
      " 46  service_ftp          131505 non-null  int64  \n",
      " 47  state_REQ            131505 non-null  int64  \n",
      " 48  tcprtt               131505 non-null  float64\n",
      " 49  state_INT            131505 non-null  int64  \n",
      " 50  ct_dst_src_ltm       131505 non-null  float64\n",
      " 51  djit                 131505 non-null  float64\n",
      " 52  dmean                131505 non-null  float64\n",
      "dtypes: float64(32), int64(21)\n",
      "memory usage: 54.2 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the function\n",
    "def knn_predict(X_train, X_test, y_train, y_test, k, p):\n",
    "    \n",
    "    # Counter to help with label votingtest_point\n",
    "    from collections import Counter\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    # Need output of 1 prediction per test data point\n",
    "    y_hat_test = []\n",
    "    \n",
    "\n",
    "    for test_point in X_test.iterrows():\n",
    "        distances = []\n",
    "\n",
    "        for train_point in X_train.iterrows():\n",
    "            distance = minkowski_distance(test_point, train_point, p=p)\n",
    "            distances.append(distance)\n",
    "        \n",
    "        # Store distances in a dataframe\n",
    "        df_dists = pd.DataFrame(data=distances, columns=['dist'], \n",
    "                                index=y_train.index)\n",
    "        \n",
    "        # Sort distances, and only consider the k closest points\n",
    "        df_nn = df_dists.sort_values(by=['dist'], axis=0)[:k]\n",
    "\n",
    "        # Create counter object to track the labels of k closest neighbors\n",
    "        counter = Counter(y_train[df_nn.index])\n",
    "\n",
    "        # Get most common label of all the nearest neighbors\n",
    "        prediction = counter.most_common()[0][0]\n",
    "        \n",
    "        # Append prediction to output list\n",
    "        y_hat_test.append(prediction)\n",
    "        \n",
    "        print(distances)\n",
    "    return y_hat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test dataset\n",
    "y_hat_test = knn_predict(X_train2, X_test2, y_train2, y_test2, k=2, p=1)\n",
    "\n",
    "#print(y_hat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model:  0.765\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy of model: \", accuracy_score(y_test2, y_hat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f963b5ca4c1eec347200b4c83f7984f43a494473bc399911aadd35d6f16d968"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
